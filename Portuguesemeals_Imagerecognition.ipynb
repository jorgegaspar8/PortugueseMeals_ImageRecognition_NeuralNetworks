{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61956af",
   "metadata": {
    "id": "e61956af"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<center> <h1> PORTUGUESE MEALS IMAGE RECOGNITION </h1> </center> <br>\n",
    "<center> DEEP LEARNING NEURAL NETWORKS | FALL SEMESTER 2022/ 2023 </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pAW032SuLQAv",
   "metadata": {
    "id": "pAW032SuLQAv"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ae39d",
   "metadata": {
    "id": "c35ae39d"
   },
   "source": [
    "**GROUP 10:** <br>\n",
    "\n",
    "- João Magalhães      `20211044` <br>\n",
    "- Maria Trindade      `20211049` <br>\n",
    "- Nuno Bolas          `20211052` <br>\n",
    "- Jorge Gaspar        `20211057` <br> \n",
    "- Mariana Teixeira    `20211058` <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a07a871",
   "metadata": {
    "id": "0a07a871"
   },
   "source": [
    "<a id='toc'></a>\n",
    "\n",
    "\n",
    "**Table of Contents** <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a149aa4",
   "metadata": {
    "id": "4a149aa4"
   },
   "source": [
    "[BACK TO TOC](#toc)\n",
    "    \n",
    "<a id='import'></a>\n",
    "\n",
    "# <font color = 'darkblue'> 1. Import</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555260b7",
   "metadata": {
    "id": "555260b7"
   },
   "source": [
    "<a class=\"anchor\" id=\"importlibraries\">\n",
    "\n",
    "## 1.1. Import Libraries\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c292e9",
   "metadata": {
    "id": "56c292e9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import Sequential, layers, initializers, regularizers, optimizers, metrics \n",
    "from keras import callbacks\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "import io\n",
    "import itertools\n",
    "from packaging import version\n",
    "import random \n",
    "import zipfile\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eab5a4",
   "metadata": {
    "id": "d6eab5a4"
   },
   "outputs": [],
   "source": [
    "# Set the style for the Seaborn's plots\n",
    "sns.set_style('whitegrid',{\n",
    "    'xtick.bottom': False,\n",
    "    'xtick.color': '.1',\n",
    "    'xtick.direction': 'out',\n",
    "    'xtick.top': False,\n",
    "    'xtick.major.size': 1,\n",
    "    'xtick.minor.size': 0.5,\n",
    "    'ytick.left': True,\n",
    "    'ytick.color': '.1',\n",
    "    'ytick.direction': 'out',\n",
    "    'ytick.right': False,\n",
    "    'ytick.major.size': 1,\n",
    "    'ytick.minor.size': 0.5,    \n",
    "    'ytick.color': '.1',\n",
    "    'grid.linestyle': '--',\n",
    "    'axes.edgecolor': '.1',\n",
    "    'grid.color': '0.8'\n",
    " })\n",
    "\n",
    "palette = sns.color_palette(\"Set2\") \n",
    "sns.set_palette(palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b95980",
   "metadata": {
    "id": "f9b95980"
   },
   "source": [
    "<a class=\"anchor\" id=\"setuptensorboard\">\n",
    "\n",
    "## 1.2. Setup Tensorboard\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3520e358",
   "metadata": {
    "id": "3520e358"
   },
   "source": [
    "Code inspired by: https://neptune.ai/blog/tensorboard-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a24ea0",
   "metadata": {
    "id": "17a24ea0"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b204c5",
   "metadata": {
    "id": "c6b204c5"
   },
   "outputs": [],
   "source": [
    "#Folder to save the logs\n",
    "log_folder = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5b384",
   "metadata": {
    "id": "45d5b384"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f802b",
   "metadata": {
    "id": "d58f802b"
   },
   "outputs": [],
   "source": [
    "#Clear previous logs\n",
    "\n",
    "#collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "#jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "#try:\n",
    "#    shutil.rmtree('logs')\n",
    "#except:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120c172b",
   "metadata": {
    "id": "120c172b"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_folder = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf17fde",
   "metadata": {
    "id": "ebf17fde"
   },
   "source": [
    "[BACK TO TOC](#toc)\n",
    "    \n",
    "<a id='dataunderstanding'></a>\n",
    "\n",
    "# <font color = 'darkblue'> 2. Data Understanding and Preprocessing </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e077650",
   "metadata": {
    "id": "0e077650"
   },
   "source": [
    "<a class=\"anchor\" id=\"loaddata\">\n",
    "\n",
    "## 2.1. Data Loading\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb1f16",
   "metadata": {
    "id": "c3cb1f16"
   },
   "outputs": [],
   "source": [
    "#Defining files path\n",
    "\n",
    "path = '../Dataset/dataset_dishes'\n",
    "\n",
    "try: \n",
    "    os.chdir(path)\n",
    "except: \n",
    "    print('Curret path is: ' + os.getcwd())\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2983b7",
   "metadata": {
    "id": "6a2983b7"
   },
   "source": [
    "Download the dataset of the dishes photos following the tensorflow tutorial for loading images https://www.tensorflow.org/tutorials/load_data/images and the notebook shown in class (t_w3_2022_drive)\n",
    "\n",
    "The dataset contains 6 subdirectories corresponding to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4e21d",
   "metadata": {
    "id": "0ed4e21d"
   },
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()\n",
    "data_dir_train = pathlib.Path(os.path.join(data_dir, \"training\"))\n",
    "data_dir_val = pathlib.Path(os.path.join(data_dir, \"validation\"))\n",
    "data_dir_test= pathlib.Path(os.path.join(data_dir, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7de1f",
   "metadata": {
    "id": "7fd7de1f"
   },
   "outputs": [],
   "source": [
    "data_dir_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa7462",
   "metadata": {
    "id": "91aa7462"
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89df03",
   "metadata": {
    "id": "da89df03"
   },
   "source": [
    "Create a dataframe and check the classes' balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55441ae",
   "metadata": {
    "id": "e55441ae"
   },
   "outputs": [],
   "source": [
    "filepaths = list(data_dir_train.glob(r'**/*.jpg')) #iterate over folders and sub-folders\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths)) #Create labels with the number of classes\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str) #create filepaths column\n",
    "labels = pd.Series(labels, name='Label') #create classes names column\n",
    "\n",
    "df = pd.concat([filepaths, labels], axis=1) #create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7711bb9",
   "metadata": {
    "id": "f7711bb9"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f426d6",
   "metadata": {
    "id": "22f426d6"
   },
   "outputs": [],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0338b8cb",
   "metadata": {
    "id": "0338b8cb"
   },
   "source": [
    "Since not every class has the same number of images, we need to sample them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cdcf9",
   "metadata": {
    "id": "288cdcf9"
   },
   "outputs": [],
   "source": [
    "# category_samples = []\n",
    "# for category in df['Label'].unique():\n",
    "#     category_slice = df.query(\"Label == @category\")\n",
    "#     category_samples.append(category_slice.sample(100, random_state=1))\n",
    "# df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8000ee",
   "metadata": {
    "id": "7e8000ee"
   },
   "outputs": [],
   "source": [
    "# df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97019b7",
   "metadata": {
    "id": "c97019b7"
   },
   "outputs": [],
   "source": [
    "# Falta fazer o exploration do dataset original, eliminar as classes que não queremos e juntar o scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31242b52",
   "metadata": {
    "id": "31242b52"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8e3e98e",
   "metadata": {
    "id": "a8e3e98e"
   },
   "source": [
    "Create the dataset with the images: Start by loading the images and spliting the dataset in training and validation using the ``tf.keras.utils.image_dataset_from_directory`` function and the validation_split=0.2 argument like shown in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c9968",
   "metadata": {
    "id": "015c9968"
   },
   "outputs": [],
   "source": [
    "# Define list of parameters:\n",
    "image_size=(128, 128) #image size (height and width)\n",
    "crop_to_aspect_ratio = True #respects the images aspect ratio when resizing. output image is cropped to fit the target aspect ratio if different\n",
    "color_mode='rgb' #default color\n",
    "batch_size=96 #no. of images loaded in each batch\n",
    "shuffle=True #randomization of the instances so each batch has the representation of the maximum no. of classes\n",
    "seed=28 #seed used for the shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e516c0a",
   "metadata": {
    "id": "5e516c0a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the train and validation datasets (80% for training and 20% validation):\n",
    "data_dir_train = '/content/drive/MyDrive/IMS_DeepLearning/dataset_dishes/training'\n",
    "data_dir_val = '/content/drive/MyDrive/IMS_DeepLearning/dataset_dishes/validation'\n",
    "\n",
    "ds_train = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "    image_size=image_size,\n",
    "    crop_to_aspect_ratio=crop_to_aspect_ratio,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle,\n",
    "    seed=seed)\n",
    "\n",
    "ds_val = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_val,\n",
    "  image_size=image_size,\n",
    "    crop_to_aspect_ratio=crop_to_aspect_ratio,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle,\n",
    "    seed=seed)\n",
    "\n",
    "class_names = ds_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903df373",
   "metadata": {
    "id": "903df373"
   },
   "outputs": [],
   "source": [
    "# Check object properties\n",
    "print(\"\\nObject's type:\\t\", type(ds_train))\n",
    "print(\"Is it a tf.data.Dataset?\\t R:\",isinstance(ds_train, tf.data.Dataset))\n",
    "print(\"Classes:\", ds_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c94d883",
   "metadata": {
    "id": "6c94d883"
   },
   "source": [
    "Checking the training dataset first nine images to get a feeling of the images' quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7cacd0",
   "metadata": {
    "id": "ad7cacd0"
   },
   "outputs": [],
   "source": [
    "#Code source: https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in ds_train.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e01bfa",
   "metadata": {
    "id": "40e01bfa"
   },
   "source": [
    "Checking the number of images per class of the training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393421a",
   "metadata": {
    "id": "c393421a"
   },
   "outputs": [],
   "source": [
    "classes = []\n",
    "for (image,label) in tuple(ds_train.unbatch()):\n",
    "    classes.append(label.numpy())\n",
    "classes = pd.Series(classes)\n",
    "count = classes.value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc613498",
   "metadata": {
    "id": "dc613498"
   },
   "outputs": [],
   "source": [
    "classes = []\n",
    "for (image,label) in tuple(ds_val.unbatch()):\n",
    "    classes.append(label.numpy())\n",
    "classes = pd.Series(classes)\n",
    "count = classes.value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4881c4a6",
   "metadata": {
    "id": "4881c4a6"
   },
   "source": [
    "Notice the training and validation datasets are imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8867b6c",
   "metadata": {
    "id": "b8867b6c"
   },
   "outputs": [],
   "source": [
    "for batch_x_train, batch_y_train in ds_train:\n",
    "    print(batch_x_train.shape, batch_y_train.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dw-QV8j5cGHL",
   "metadata": {
    "id": "Dw-QV8j5cGHL"
   },
   "outputs": [],
   "source": [
    "for batch_x_val, batch_y_val in ds_val:\n",
    "    print(batch_x_val.shape, batch_y_val.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7bc7ad",
   "metadata": {
    "id": "cd7bc7ad"
   },
   "source": [
    "batch_x_train is a tensor with a batch of 64 images of shape 128x128 and color channel RGB 3. batch_y_train is a tensor with 64 images and corresponding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5386c",
   "metadata": {
    "id": "ccc5386c"
   },
   "source": [
    "<a class=\"anchor\" id=\"Datapreprocessing\">\n",
    "\n",
    "## 2.2. Data Preprocessing\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e4218",
   "metadata": {
    "id": "cb0e4218"
   },
   "source": [
    "Encoding the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xYIUyvt6X20A",
   "metadata": {
    "id": "xYIUyvt6X20A"
   },
   "outputs": [],
   "source": [
    "encoding = layers.CategoryEncoding(num_tokens=6, output_mode=\"one_hot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oqjzk01rYEGN",
   "metadata": {
    "id": "oqjzk01rYEGN"
   },
   "outputs": [],
   "source": [
    "ds_train_encoded = ds_train.map(lambda x, y: (x, encoding(y)))\n",
    "batch_x_train_encoded, batch_y_train_encoded = next(iter(ds_train_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_WJZgox8YiGO",
   "metadata": {
    "id": "_WJZgox8YiGO"
   },
   "outputs": [],
   "source": [
    "ds_val_encoded = ds_val.map(lambda x, y: (x, encoding(y)))\n",
    "batch_x_val_encoded, batch_y_val_encoded = next(iter(ds_val_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf6b3f",
   "metadata": {
    "id": "82bf6b3f"
   },
   "source": [
    "Rescaling the train and validation datatsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02246238",
   "metadata": {
    "id": "02246238"
   },
   "outputs": [],
   "source": [
    "rescaling = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90298a3",
   "metadata": {
    "id": "e90298a3"
   },
   "outputs": [],
   "source": [
    "ds_train_scaled = ds_train_encoded.map(lambda x, y: (rescaling(x), y))\n",
    "batch_x_train_scaled, batch_y_train_scaled = next(iter(ds_train_scaled))\n",
    "\n",
    "\n",
    "print(np.min(batch_x_train_scaled), np.max(batch_x_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe5487",
   "metadata": {
    "id": "0afe5487"
   },
   "outputs": [],
   "source": [
    "ds_val_scaled = ds_val_encoded.map(lambda x, y: (rescaling(x), y))\n",
    "batch_x_val_scaled, batch_y_val_scaled = next(iter(ds_val_scaled))\n",
    "\n",
    "\n",
    "print(np.min(batch_x_val_scaled), np.max(batch_x_val_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014367d1",
   "metadata": {
    "id": "014367d1"
   },
   "source": [
    "<a class=\"anchor\" id=\"Dataaugmentation\">\n",
    "\n",
    "### *2.2.1 Data Augmentation*\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84368bca",
   "metadata": {
    "id": "84368bca"
   },
   "source": [
    "Data augmentation techniques allow to include diversity and increase quality of the training dataset without the need for further data through the random transformations. Since the dataset used is small, data augmentation is particularly important to train the model.<br>\n",
    "Following the notebook solved in class, we defined a data augmentation pipeline with the layers: \n",
    "-  `tf.keras.layers.RandomFlip`\n",
    "\n",
    "-  `tf.keras.layers.RandomTranslation`\n",
    "\n",
    "-  `tf.keras.layers.RandomRotation`\n",
    "\n",
    "-  `tf.keras.layers.RandomZoom`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ac81b",
   "metadata": {
    "id": "625ac81b"
   },
   "outputs": [],
   "source": [
    "augmentation = Sequential([layers.RandomFlip(seed=seed), \n",
    "                           layers.RandomRotation(0.1, seed=seed), \n",
    "                           layers.RandomZoom(0.1, seed=seed),\n",
    "                           layers.RandomTranslation(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1))], \n",
    "                           name=\"augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b09dffe",
   "metadata": {
    "id": "3b09dffe"
   },
   "source": [
    "Showing a sample image with the data augmentation pipeline applied (as the layers defined only implement data augmentation during the training, to test it, the training must be set to True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f217af1",
   "metadata": {
    "id": "4f217af1"
   },
   "outputs": [],
   "source": [
    "plt.imshow(tf.cast(augmentation(batch_x_train[0], training=True), tf.int32)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb86a8",
   "metadata": {
    "id": "4cbb86a8"
   },
   "source": [
    "Using the function defined in class to visualize the pipeline defined applied on a set of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613978b0",
   "metadata": {
    "id": "613978b0"
   },
   "outputs": [],
   "source": [
    "def show_sample_batch(ds, augmentation, grid_size=(4, 4), figsize=(14, 10)):\n",
    "    n_images = grid_size[0]\n",
    "    # Get a batch via iteration\n",
    "    iter_ = iter(ds)\n",
    "    batch_x, batch_y = iter_.next()\n",
    "    batch_x, batch_y = batch_x[0:n_images], batch_y[0:n_images]\n",
    "    # Plot the images\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    count = 0\n",
    "    for i, (img, y) in enumerate(zip(batch_x, batch_y)):\n",
    "        img_ = tf.cast(img, tf.int32)\n",
    "        for j in range(grid_size[1]):\n",
    "            # Prepare the image\n",
    "            if j>0:\n",
    "                img_ = tf.cast(augmentation(img_, training=True), tf.int32)\n",
    "            ax = plt.subplot(grid_size[0], grid_size[1],  count + 1)        \n",
    "            plt.imshow(img_)\n",
    "            plt.title(\"{} {} image of class \\\"{}\\\"\".format(\n",
    "                img.shape, \"original\" if j==0 else \"augmented\", y), size=6)\n",
    "            plt.axis(\"off\")\n",
    "            count+=1\n",
    "\n",
    "show_sample_batch(ds_train, augmentation=augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa765f0",
   "metadata": {
    "id": "9fa765f0"
   },
   "source": [
    "[BACK TO TOC](#toc)\n",
    "    \n",
    "<a id='modelling'></a>\n",
    "\n",
    "# <font color = 'darkblue'> 3. Modelling </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A_Tl191TpquY",
   "metadata": {
    "id": "A_Tl191TpquY"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv1\">\n",
    "\n",
    "## 3.0. Pre-modelling\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b94aa",
   "metadata": {
    "id": "da4b94aa"
   },
   "source": [
    "Configure dataset for performance (https://www.tensorflow.org/tutorials/load_data/images):\n",
    "- `Dataset.cache` keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model.\n",
    "- `Dataset.prefetch`overlaps data preprocessing and model execution while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cfcca8",
   "metadata": {
    "id": "c9cfcca8"
   },
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# ds_train = ds_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# ds_val = ds_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NM-sirjM-VGL",
   "metadata": {
    "id": "NM-sirjM-VGL"
   },
   "outputs": [],
   "source": [
    "#Shared parameters:\n",
    "epochs=100\n",
    "batch_size=96\n",
    "suffle= True\n",
    "input_shape = batch_x_train_scaled.shape\n",
    "n_classes=6\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9892d89",
   "metadata": {
    "id": "e9892d89"
   },
   "source": [
    "Calculate the evaluation weights for each class (since the dataset is no balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b31c0fe",
   "metadata": {
    "id": "7b31c0fe"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(batch_y_train.numpy()), y= batch_y_train.numpy())\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821d053",
   "metadata": {
    "id": "2821d053"
   },
   "outputs": [],
   "source": [
    "weights= dict(enumerate(class_weights.flatten(), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vlHCQIGfKV-r",
   "metadata": {
    "id": "vlHCQIGfKV-r"
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ON5ONHM2Mncr",
   "metadata": {
    "id": "ON5ONHM2Mncr"
   },
   "outputs": [],
   "source": [
    "val_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(batch_y_val.numpy()), y= batch_y_val.numpy())\n",
    "\n",
    "val_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MAQwGEgarZGV",
   "metadata": {
    "id": "MAQwGEgarZGV"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cb0639",
   "metadata": {
    "id": "35cb0639"
   },
   "source": [
    "Define function for confusion matrix inspired by: https://neptune.ai/blog/tensorboard-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d751a9f",
   "metadata": {
    "id": "9d751a9f"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    threshold = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d133a",
   "metadata": {
    "id": "f77d133a"
   },
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "\n",
    "    digit = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    digit = tf.expand_dims(digit, 0)\n",
    "\n",
    "    return digit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba17414",
   "metadata": {
    "id": "aba17414"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv1\">\n",
    "\n",
    "## 3.1. CNN_V1\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59726d89",
   "metadata": {
    "id": "59726d89"
   },
   "outputs": [],
   "source": [
    "#Clear previous logs\n",
    "\n",
    "#collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "#jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "#try:\n",
    "#    shutil.rmtree('logs')\n",
    "#except:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b45d42",
   "metadata": {
    "id": "a8b45d42"
   },
   "outputs": [],
   "source": [
    "# Architecture v1\n",
    "cnn1 = Sequential([# Feature extraction                   \n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   # Classification \n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "\n",
    "# Builds the DAG (comment if input_shape was already provided to the first layer)\n",
    "cnn1.build(input_shape)\n",
    "# Check network\n",
    "cnn1.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858a27b",
   "metadata": {
    "id": "0858a27b"
   },
   "outputs": [],
   "source": [
    "model=cnn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ngj73YqpO3nP",
   "metadata": {
    "id": "Ngj73YqpO3nP"
   },
   "outputs": [],
   "source": [
    "cnn1.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RVF08QdraD5e",
   "metadata": {
    "id": "RVF08QdraD5e"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78f66a",
   "metadata": {
    "id": "ef78f66a"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn1.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2f0c0",
   "metadata": {
    "id": "11d2f0c0"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab39e7d",
   "metadata": {
    "id": "9ab39e7d"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae9f13",
   "metadata": {
    "id": "e2ae9f13"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7124027",
   "metadata": {
    "id": "b7124027"
   },
   "outputs": [],
   "source": [
    "# Model training (v1)\n",
    "#Adding early stopping to help choosing the best number of epochs\n",
    "#code from: https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/\n",
    "\n",
    "#Train\n",
    "history1 = cnn1.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740791f",
   "metadata": {
    "id": "8740791f"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edc5c9e",
   "metadata": {
    "id": "5edc5c9e"
   },
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd572dc",
   "metadata": {
    "id": "ccd572dc"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist1 = pd.DataFrame.from_dict(history1.history)\n",
    "df_hist1[\"Epoch\"] = np.arange(1, len(df_hist1) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax = df_hist1.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81974e5f",
   "metadata": {
    "id": "81974e5f"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv2\">\n",
    "\n",
    "## 3.2. CNN_V2 , Batch Normalization\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a698d56",
   "metadata": {
    "id": "2a698d56"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oRgd0I-8z7Q8",
   "metadata": {
    "id": "oRgd0I-8z7Q8"
   },
   "source": [
    "### stabilizing input features of a deep network.\n",
    "From [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, by Sergey Ioffe, Christian Szegedy](https://arxiv.org/abs/1502.03167):\n",
    "\n",
    "    \"Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs.\"\n",
    "\n",
    "\n",
    "Adds ``BatchNormalization()`` layers before applying the non-linearities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29YKs90qybC5",
   "metadata": {
    "id": "29YKs90qybC5"
   },
   "outputs": [],
   "source": [
    "# Architecture v2\n",
    "cnn2_1 = Sequential([# The batch normalization layer\n",
    "                   #layers.Input(input_shape[1:]), \n",
    "                   layers.BatchNormalization(),                   \n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3), #input_shape=input_shape[1:],\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.BatchNormalization(),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.BatchNormalization(),   \n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   # Classification\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "\n",
    "# Builds the DAG (comment if input_shape was already provided to the first layer)\n",
    "cnn2_1.build(input_shape)\n",
    "# Check network\n",
    "cnn2_1.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877dcd2",
   "metadata": {
    "id": "c877dcd2"
   },
   "outputs": [],
   "source": [
    "model=cnn2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "odCe6_Xoh412",
   "metadata": {
    "id": "odCe6_Xoh412"
   },
   "outputs": [],
   "source": [
    "cnn2_1.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bce88f",
   "metadata": {
    "id": "36bce88f"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn2_1.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407509cf",
   "metadata": {
    "id": "407509cf"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd8ba61",
   "metadata": {
    "id": "dfd8ba61"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffffcd2",
   "metadata": {
    "id": "1ffffcd2"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UfZPi-sLh413",
   "metadata": {
    "id": "UfZPi-sLh413"
   },
   "outputs": [],
   "source": [
    "# Model training (v2)\n",
    "\n",
    "\n",
    "#Train\n",
    "history2_1 = cnn2_1.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191ae81",
   "metadata": {
    "id": "5191ae81"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SU7sP0Glh413",
   "metadata": {
    "id": "SU7sP0Glh413"
   },
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kP3Vp3Bsh413",
   "metadata": {
    "id": "kP3Vp3Bsh413"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist2_1 = pd.DataFrame.from_dict(history2_1.history)\n",
    "df_hist2_1[\"Epoch\"] = np.arange(1, len(df_hist2_1) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax = df_hist2_1.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a_Uty-Oe0J7u",
   "metadata": {
    "id": "a_Uty-Oe0J7u"
   },
   "source": [
    "### BatchNormalization() layer to the head of the Sequential() model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1280d20",
   "metadata": {
    "id": "c1280d20"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pHWEesN_h412",
   "metadata": {
    "id": "pHWEesN_h412"
   },
   "outputs": [],
   "source": [
    "# Architecture v2.2\n",
    "cnn2_2 = Sequential([# The batch normalization layer \n",
    "                   layers.BatchNormalization(),     \n",
    "                   #layers.Input(input_shape[1:]),\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3), #input_shape=input_shape[1:],\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   # Classification (use units=n_classes, activation=\"softmax\" for multi-class problems)\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "\n",
    "# Builds the DAG (comment if input_shape was already provided to the first layer)\n",
    "cnn2_2.build(input_shape)\n",
    "# Check network\n",
    "cnn2_2.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425df6e0",
   "metadata": {
    "id": "425df6e0"
   },
   "outputs": [],
   "source": [
    "model=cnn2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iQ6X5cLNyoEH",
   "metadata": {
    "id": "iQ6X5cLNyoEH"
   },
   "outputs": [],
   "source": [
    "cnn2_2.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6afd0c",
   "metadata": {
    "id": "aa6afd0c"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d244de",
   "metadata": {
    "id": "f5d244de"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn2_2.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581a406",
   "metadata": {
    "id": "2581a406"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833efb7",
   "metadata": {
    "id": "0833efb7"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f316a651",
   "metadata": {
    "id": "f316a651"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ag-ylzqByoEI",
   "metadata": {
    "id": "ag-ylzqByoEI"
   },
   "outputs": [],
   "source": [
    "# Model training (v2)\n",
    "\n",
    "#Train\n",
    "\n",
    "history2_2 = cnn2_2.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c60475",
   "metadata": {
    "id": "62c60475"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FvuT3ho7yoEJ",
   "metadata": {
    "id": "FvuT3ho7yoEJ"
   },
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1gG8JUOiyoEJ",
   "metadata": {
    "id": "1gG8JUOiyoEJ"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist2_2 = pd.DataFrame.from_dict(history2_2.history)\n",
    "df_hist2_2[\"Epoch\"] = np.arange(1, len(df_hist2_2) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax = df_hist2_2.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744709bc",
   "metadata": {
    "id": "744709bc"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv3\">\n",
    "\n",
    "## 3.3. CNN_V3, data augmentation\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268baf54",
   "metadata": {
    "id": "268baf54"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb90f62",
   "metadata": {
    "id": "1fb90f62"
   },
   "outputs": [],
   "source": [
    "for layer in augmentation.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db198b",
   "metadata": {
    "id": "a5db198b"
   },
   "outputs": [],
   "source": [
    "# Architecture v3\n",
    "cnn3 = Sequential([# Add data augmentation\n",
    "                   augmentation,                         \n",
    "                   # Feature extraction\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   # Classification (use units=n_classes, activation=\"softmax\" for multi-class)\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "# Builds the DAG (comment if input_shape was already provided to the first layer)\n",
    "cnn3.build(input_shape)\n",
    "# Check network\n",
    "cnn3.summary()  # alternatively use tf.keras.utils.plot_model(cnn1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea44daa",
   "metadata": {
    "id": "5ea44daa"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "cnn3.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a862fa",
   "metadata": {
    "id": "f4a862fa"
   },
   "outputs": [],
   "source": [
    "model=cnn3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d281da3",
   "metadata": {
    "id": "9d281da3"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9118868",
   "metadata": {
    "id": "d9118868"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn3.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2e660",
   "metadata": {
    "id": "72f2e660"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81072343",
   "metadata": {
    "id": "81072343"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e50a9",
   "metadata": {
    "id": "978e50a9"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6d1ce",
   "metadata": {
    "id": "afe6d1ce"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Train\n",
    "history3 = cnn3.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb9962",
   "metadata": {
    "id": "03fb9962"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20a2e8",
   "metadata": {
    "id": "7e20a2e8"
   },
   "outputs": [],
   "source": [
    "df_hist3 = pd.DataFrame.from_dict(history3.history)\n",
    "df_hist3[\"Epoch\"] = np.arange(1, len(df_hist3) + 1, 1)\n",
    "# 4.\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax = df_hist3.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                  secondary_y = secondary_y,\n",
    "                  kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                  ylabel=\"Cross-entropy\", \n",
    "                  xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                  color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax.right_ax.set_ylim(0.45, 1.05)\n",
    "ax.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47742f",
   "metadata": {
    "id": "ed47742f"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv4\">\n",
    "\n",
    "## 3.4. CNN_V4 , without pre-processing\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceccbbc7",
   "metadata": {
    "id": "ceccbbc7"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc7c46",
   "metadata": {
    "id": "b9dc7c46"
   },
   "outputs": [],
   "source": [
    "input_shape_nopre = batch_x_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d061b",
   "metadata": {
    "id": "250d061b"
   },
   "outputs": [],
   "source": [
    "# Architecture v4\n",
    "cnn4 = Sequential([       \n",
    "                   #layers.Input(input_shape[1:]),\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   # Classification\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "\n",
    "# Builds the DAG\n",
    "cnn4.build(input_shape_nopre)\n",
    "# Check network\n",
    "cnn4.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2b4de",
   "metadata": {
    "id": "fcb2b4de"
   },
   "outputs": [],
   "source": [
    "model=cnn4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f8793b",
   "metadata": {
    "id": "46f8793b"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943c482",
   "metadata": {
    "id": "2943c482"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn4.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77bf01",
   "metadata": {
    "id": "5c77bf01"
   },
   "outputs": [],
   "source": [
    "# logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# # Defining the basic TensorBoard callback.\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "# file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451bc8f5",
   "metadata": {
    "id": "451bc8f5"
   },
   "outputs": [],
   "source": [
    "# def log_confusion_matrix(epoch, logs):\n",
    "#     predictions_raw = model.predict(batch_x_val_scaled)\n",
    "#     predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "#     cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "#     figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "#     cm_image = plot_to_image(figure)\n",
    "\n",
    "#     with file_writer_cm.as_default():\n",
    "#         tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78241fb1",
   "metadata": {
    "id": "78241fb1"
   },
   "outputs": [],
   "source": [
    "# # Defining the per-epoch callback.\n",
    "# cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qsniq8NcPs2G",
   "metadata": {
    "id": "Qsniq8NcPs2G"
   },
   "outputs": [],
   "source": [
    "# Model training (v1)\n",
    "#Adding early stopping to help choosing the best number of epochs\n",
    "#code from: https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/\n",
    "\n",
    "cnn4.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])\n",
    "\n",
    "#Train\n",
    "history4 = cnn4.fit(ds_train_encoded,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=ds_val_encoded,\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint])#, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cee3a2",
   "metadata": {
    "id": "19cee3a2"
   },
   "outputs": [],
   "source": [
    "# #Star tensorboard\n",
    "\n",
    "# %tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J37blBQoPs2R",
   "metadata": {
    "id": "J37blBQoPs2R"
   },
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N-Kzndh4Ps2R",
   "metadata": {
    "id": "N-Kzndh4Ps2R"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist4 = pd.DataFrame.from_dict(history4.history)\n",
    "df_hist4[\"Epoch\"] = np.arange(1, len(df_hist4) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax = df_hist4.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l8ZiRxJC9AeD",
   "metadata": {
    "id": "l8ZiRxJC9AeD"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv5\">\n",
    "\n",
    "## 3.5. CNN_V5, layers\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8803c7",
   "metadata": {
    "id": "5c8803c7"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f38b53",
   "metadata": {
    "id": "21f38b53"
   },
   "outputs": [],
   "source": [
    "# Architecture v5\n",
    "cnn5 = Sequential([# The batch normalization layer \n",
    "                   layers.BatchNormalization(),                           \n",
    "                   # Feature extraction: first block\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: second block\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: third block\n",
    "                   layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: fourth (closing) block\n",
    "                   layers.Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),                   \n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   # Classification\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "# Builds the DAG \n",
    "cnn5.build(input_shape)\n",
    "# Check network\n",
    "cnn5.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb3b88",
   "metadata": {
    "id": "ffbb3b88"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "cnn5.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de468baa",
   "metadata": {
    "id": "de468baa"
   },
   "outputs": [],
   "source": [
    "model=cnn5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c884d9b3",
   "metadata": {
    "id": "c884d9b3"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0bd481",
   "metadata": {
    "id": "3d0bd481"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn5.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac454ed",
   "metadata": {
    "id": "9ac454ed"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8530a",
   "metadata": {
    "id": "47a8530a"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332337f",
   "metadata": {
    "id": "c332337f"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d99ad",
   "metadata": {
    "id": "856d99ad"
   },
   "outputs": [],
   "source": [
    "# Model training (v5)\n",
    "\n",
    "#Train\n",
    "\n",
    "history5 = cnn5.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f7873f",
   "metadata": {
    "id": "f0f7873f"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7dc43",
   "metadata": {
    "id": "57a7dc43"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist5 = pd.DataFrame.from_dict(history5.history)\n",
    "df_hist5[\"Epoch\"] = np.arange(1, len(df_hist5) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax5 = df_hist5.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax5.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax5.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax5.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eWNdJSQ330_",
   "metadata": {
    "id": "3eWNdJSQ330_"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv6\">\n",
    "\n",
    "## 3.6. CNN_V6, drop-out\n",
    "\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa125d",
   "metadata": {
    "id": "60fa125d"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OU9iv6asqiv4",
   "metadata": {
    "id": "OU9iv6asqiv4"
   },
   "source": [
    "#### Drop-out 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3MUvav7X4TFA",
   "metadata": {
    "id": "3MUvav7X4TFA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/\n",
    "#https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
    "#drop-out rate: divide the number of nodes in the layer before dropout by the proposed dropout rate and use that as the number of nodes in the new \n",
    "#network that uses dropout. For example, a network with 100 nodes and a proposed dropout rate of 0.5 will require 200 nodes (100 / 0.5) when using dropout.\n",
    "\n",
    "# Architecture v5\n",
    "cnn6_1 = Sequential([# The batch normalization layer \n",
    "                   layers.BatchNormalization(),                           \n",
    "                   # Feature extraction: first block\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: second block\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: third block\n",
    "                   layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: fourth (closing) block\n",
    "                   layers.Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),                   \n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   #drop-out\n",
    "                   layers.Dropout(0.5), \n",
    "                   # Classification\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "# Builds the DAG \n",
    "cnn6_1.build(input_shape)\n",
    "# Check network\n",
    "cnn6_1.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Lto9zG94TFB",
   "metadata": {
    "id": "-Lto9zG94TFB"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "cnn6_1.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791e384",
   "metadata": {
    "id": "f791e384"
   },
   "outputs": [],
   "source": [
    "model=cnn6_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1ed08",
   "metadata": {
    "id": "83b1ed08"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49d8770",
   "metadata": {
    "id": "b49d8770"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn6_1.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e0bc7",
   "metadata": {
    "id": "dd6e0bc7"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63c0d0",
   "metadata": {
    "id": "da63c0d0"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805de22",
   "metadata": {
    "id": "b805de22"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_qH6CD8E4TFB",
   "metadata": {
    "id": "_qH6CD8E4TFB"
   },
   "outputs": [],
   "source": [
    "# Model training (v6)\n",
    "#Train\n",
    "\n",
    "history6__1 = cnn6_1.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e322601",
   "metadata": {
    "id": "2e322601"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DS269Z044TFB",
   "metadata": {
    "id": "DS269Z044TFB"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist6_1 = pd.DataFrame.from_dict(history6__1.history)\n",
    "df_hist6_1[\"Epoch\"] = np.arange(1, len(df_hist6_1) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax6_1 = df_hist6_1.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax6_1.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax6_1.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax6_1.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "teJEB-Taqwk_",
   "metadata": {
    "id": "teJEB-Taqwk_"
   },
   "source": [
    "#### Drop-out 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b4b6e",
   "metadata": {
    "id": "161b4b6e"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q_SY-Fw3q4nT",
   "metadata": {
    "id": "q_SY-Fw3q4nT"
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/\n",
    "#https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
    "#drop-out rate: divide the number of nodes in the layer before dropout by the proposed dropout rate and use that as the number of nodes in the new \n",
    "#network that uses dropout. For example, a network with 100 nodes and a proposed dropout rate of 0.5 will require 200 nodes (100 / 0.5) when using dropout.\n",
    "# Architecture v5\n",
    "cnn6_2 = Sequential([# The batch normalization layer \n",
    "                   layers.BatchNormalization(),                           \n",
    "                   # Feature extraction: first block\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: second block\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: third block\n",
    "                   layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: fourth (closing) block\n",
    "                   layers.Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),                   \n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   #drop-out\n",
    "                   layers.Dropout(0.8), \n",
    "                   # Classification\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "# Builds the DAG \n",
    "cnn6_2.build(input_shape)\n",
    "# Check network\n",
    "cnn6_2.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48AHK7uoq4nT",
   "metadata": {
    "id": "48AHK7uoq4nT"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "cnn6_2.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88256199",
   "metadata": {
    "id": "88256199"
   },
   "outputs": [],
   "source": [
    "model=cnn6_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5fdf8",
   "metadata": {
    "id": "9fb5fdf8"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01ba9f",
   "metadata": {
    "id": "4a01ba9f"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn6_2.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49942377",
   "metadata": {
    "id": "49942377"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136147c0",
   "metadata": {
    "id": "136147c0"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2bd6a",
   "metadata": {
    "id": "a9a2bd6a"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dgvd17vjq4nU",
   "metadata": {
    "id": "Dgvd17vjq4nU"
   },
   "outputs": [],
   "source": [
    "# Model training (v6)\n",
    "\n",
    "#Train\n",
    "\n",
    "history6_2 = cnn6_2.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b4ad36",
   "metadata": {
    "id": "58b4ad36"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UOoMry-eq4nU",
   "metadata": {
    "id": "UOoMry-eq4nU"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist6_2 = pd.DataFrame.from_dict(history6_2.history)\n",
    "df_hist6_2[\"Epoch\"] = np.arange(1, len(df_hist6_2) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax6_2 = df_hist6_2.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax6_2.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax6_2.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax6_2.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LmyE08xRq0yh",
   "metadata": {
    "id": "LmyE08xRq0yh"
   },
   "source": [
    " #### Drop-out 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865e18f",
   "metadata": {
    "id": "e865e18f"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fnbJ8vnpq71D",
   "metadata": {
    "id": "fnbJ8vnpq71D"
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/\n",
    "#https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
    "#drop-out rate: divide the number of nodes in the layer before dropout by the proposed dropout rate and use that as the number of nodes in the new \n",
    "#network that uses dropout. For example, a network with 100 nodes and a proposed dropout rate of 0.5 will require 200 nodes (100 / 0.5) when using dropout.\n",
    "\n",
    "# Architecture v5\n",
    "cnn6_3 = Sequential([# The batch normalization layer \n",
    "                   layers.BatchNormalization(),                           \n",
    "                   # Feature extraction: first block\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: second block\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: third block\n",
    "                   layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: fourth (closing) block\n",
    "                   layers.Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),                   \n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   #drop-out\n",
    "                   layers.Dropout(0.5), \n",
    "                   # Classification\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "# Builds the DAG \n",
    "cnn6_3.build(input_shape)\n",
    "# Check network\n",
    "cnn6_3.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kShbw3Naq71D",
   "metadata": {
    "id": "kShbw3Naq71D"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "cnn6_3.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5623a",
   "metadata": {
    "id": "7ce5623a"
   },
   "outputs": [],
   "source": [
    "model=cnn6_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e93c11",
   "metadata": {
    "id": "c9e93c11"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e6925",
   "metadata": {
    "id": "a19e6925"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn6_3.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32a478",
   "metadata": {
    "id": "4c32a478"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e122f5",
   "metadata": {
    "id": "b7e122f5"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa1724",
   "metadata": {
    "id": "9eaa1724"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VsJzVIHzq71E",
   "metadata": {
    "id": "VsJzVIHzq71E"
   },
   "outputs": [],
   "source": [
    "# Model training (v6)\n",
    "\n",
    "#Train\n",
    "\n",
    "history6_3 = cnn6_3.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5bf9af",
   "metadata": {
    "id": "2a5bf9af"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PQs7OI2Pq71E",
   "metadata": {
    "id": "PQs7OI2Pq71E"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist6_3 = pd.DataFrame.from_dict(history6_3.history)\n",
    "df_hist6_3[\"Epoch\"] = np.arange(1, len(df_hist6_3) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax6_3 = df_hist6_3.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax6_3.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax6_3.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax6_3.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UeEZprbWiygK",
   "metadata": {
    "id": "UeEZprbWiygK"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv6\">\n",
    "\n",
    "## 3.6. CNN_V7, layer weight regularization\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30fb1a",
   "metadata": {
    "id": "5b30fb1a"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qLKVx9cC2jw4",
   "metadata": {
    "id": "qLKVx9cC2jw4"
   },
   "outputs": [],
   "source": [
    "# Architecture v7\n",
    "\n",
    "cnn7 = Sequential([# The batch normalization layer \n",
    "                   layers.BatchNormalization(),                           \n",
    "                   # Feature extraction: first block\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                 bias_regularizer=regularizers.L2(1e-4),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: second block\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                 bias_regularizer=regularizers.L2(1e-4),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: third block\n",
    "                   layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                                 kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                 bias_regularizer=regularizers.L2(1e-4),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: fourth (closing) block\n",
    "                   layers.Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                                 kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                 bias_regularizer=regularizers.L2(1e-4),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),                   \n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   # Classification\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                bias_regularizer=regularizers.L2(1e-4),\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "# Builds the DAG \n",
    "cnn7.build(input_shape)\n",
    "# Check network\n",
    "cnn7.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g1VIpe2U5-yK",
   "metadata": {
    "id": "g1VIpe2U5-yK"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "cnn7.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d8625",
   "metadata": {
    "id": "eb9d8625"
   },
   "outputs": [],
   "source": [
    "model=cnn7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993d82b2",
   "metadata": {
    "id": "993d82b2"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef48c87",
   "metadata": {
    "id": "4ef48c87"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn7.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b229b7",
   "metadata": {
    "id": "07b229b7"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea6329",
   "metadata": {
    "id": "4fea6329"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6f3e9",
   "metadata": {
    "id": "6ec6f3e9"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3oegzT45-yV",
   "metadata": {
    "id": "c3oegzT45-yV"
   },
   "outputs": [],
   "source": [
    "# Model training (v7)\n",
    "\n",
    "#Train\n",
    "\n",
    "history7 = cnn7.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c641bb2",
   "metadata": {
    "id": "9c641bb2"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ptB299045-yV",
   "metadata": {
    "id": "ptB299045-yV"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist7 = pd.DataFrame.from_dict(history7.history)\n",
    "df_hist7[\"Epoch\"] = np.arange(1, len(df_hist7) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax7 = df_hist7.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax7.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax7.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax7.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a145163e",
   "metadata": {
    "id": "a145163e"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv4\">\n",
    "\n",
    "## 3.8. CNN_V8, Combining best methods\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc267395",
   "metadata": {
    "id": "fc267395"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a9405",
   "metadata": {
    "id": "4f2a9405"
   },
   "source": [
    "#### Drop-out with Batch Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ad8b0",
   "metadata": {
    "id": "173ad8b0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/\n",
    "#https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf\n",
    "#drop-out rate: divide the number of nodes in the layer before dropout by the proposed dropout rate and use that as the number of nodes in the new \n",
    "#network that uses dropout. For example, a network with 100 nodes and a proposed dropout rate of 0.5 will require 200 nodes (100 / 0.5) when using dropout.\n",
    "\n",
    "# Architecture v6\n",
    "cnn8 = Sequential([# The batch normalization layer \n",
    "                   layers.BatchNormalization(),                           \n",
    "                   # Feature extraction: first block\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.BatchNormalization(),\n",
    "                   layers.Activation(\"relu\"),                   \n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: second block\n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.BatchNormalization(),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: third block\n",
    "                   layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.BatchNormalization(),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: fourth (closing) block\n",
    "                   layers.Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.BatchNormalization(),\n",
    "                   layers.Activation(\"relu\"),                   \n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   #drop-out\n",
    "                   layers.Dropout(0.5), \n",
    "                   # Classification\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "# Builds the DAG \n",
    "cnn8.build(input_shape)\n",
    "# Check network\n",
    "cnn8.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed32771",
   "metadata": {
    "id": "fed32771"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "cnn8.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94533ce",
   "metadata": {
    "id": "f94533ce"
   },
   "outputs": [],
   "source": [
    "model=cnn8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bb37c3",
   "metadata": {
    "id": "c6bb37c3"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abb377",
   "metadata": {
    "id": "55abb377"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn8.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da80a0",
   "metadata": {
    "id": "07da80a0"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da957ed8",
   "metadata": {
    "id": "da957ed8"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251958c2",
   "metadata": {
    "id": "251958c2"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68d5d8",
   "metadata": {
    "id": "4d68d5d8"
   },
   "outputs": [],
   "source": [
    "# Model training (v5)\n",
    "#Train\n",
    "\n",
    "history8 = cnn8.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eadbe2",
   "metadata": {
    "id": "b7eadbe2"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d672a5e",
   "metadata": {
    "id": "6d672a5e"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist8 = pd.DataFrame.from_dict(history8.history)\n",
    "df_hist8[\"Epoch\"] = np.arange(1, len(df_hist8) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax6 = df_hist8.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax6.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax6.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax6.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1QSMWSF5lVFu",
   "metadata": {
    "id": "1QSMWSF5lVFu"
   },
   "source": [
    "## CNN8_2 (Batch Normalization + Layers + Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wc1CLf-5lcKK",
   "metadata": {
    "id": "Wc1CLf-5lcKK"
   },
   "outputs": [],
   "source": [
    "cnn8_2 = Sequential([# The batch normalization layer \n",
    "                   layers.BatchNormalization(),                           \n",
    "                   # Feature extraction: first block\n",
    "                   layers.Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                                 kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                 bias_regularizer=regularizers.L2(1e-4),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: second block\n",
    "                   layers.BatchNormalization(),     \n",
    "                   layers.Conv2D(filters=64, kernel_size=(3, 3),\n",
    "                                 kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                 bias_regularizer=regularizers.L2(1e-4),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: third block\n",
    "                   layers.BatchNormalization(),     \n",
    "                   layers.Conv2D(filters=128, kernel_size=(3, 3),\n",
    "                                 kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                 bias_regularizer=regularizers.L2(1e-4),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),\n",
    "                   layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                   # Feature extraction: fourth (closing) block\n",
    "                   layers.BatchNormalization(),     \n",
    "                   layers.Conv2D(filters=256, kernel_size=(3, 3),\n",
    "                                 kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                 bias_regularizer=regularizers.L2(1e-4),\n",
    "                                 kernel_initializer=initializers.GlorotNormal(seed=seed)),\n",
    "                   layers.Activation(\"relu\"),                   \n",
    "                   layers.GlobalMaxPooling2D(),\n",
    "                   layers.Dropout(0.5),   \n",
    "                   #drop-out\n",
    "                   # Classification\n",
    "                   layers.Dense(units=n_classes, activation=\"softmax\",\n",
    "                                kernel_regularizer=regularizers.L2(1e-4),\n",
    "                                bias_regularizer=regularizers.L2(1e-4),\n",
    "                                kernel_initializer=initializers.GlorotNormal(seed=seed))])\n",
    "# Builds the DAG \n",
    "cnn8_2.build(input_shape)\n",
    "# Check network\n",
    "cnn8_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Oxl7bmRmoiQ6",
   "metadata": {
    "id": "Oxl7bmRmoiQ6"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "cnn8_2.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OfVL0hx0oiQ6",
   "metadata": {
    "id": "OfVL0hx0oiQ6"
   },
   "outputs": [],
   "source": [
    "model=cnn8_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jqUtoF75oiQ7",
   "metadata": {
    "id": "jqUtoF75oiQ7"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VjiWYFmJoiQ7",
   "metadata": {
    "id": "VjiWYFmJoiQ7"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'cnn8_2.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OnJOjonMoiQ7",
   "metadata": {
    "id": "OnJOjonMoiQ7"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGGqGoSHoiQ7",
   "metadata": {
    "id": "RGGqGoSHoiQ7"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n8jm7loQoiQ8",
   "metadata": {
    "id": "n8jm7loQoiQ8"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VRmmylJsoiQ8",
   "metadata": {
    "id": "VRmmylJsoiQ8"
   },
   "outputs": [],
   "source": [
    "# Model training (v5)\n",
    "#Train\n",
    "\n",
    "history8_2 = cnn8_2.fit(ds_train_scaled,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    validation_data=(batch_x_val_scaled,batch_y_val_scaled),\n",
    "                    class_weight=weights,\n",
    "                    callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I8fDQfQPoiQ8",
   "metadata": {
    "id": "I8fDQfQPoiQ8"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rj9tUUaLoiQ8",
   "metadata": {
    "id": "Rj9tUUaLoiQ8"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist8_2 = pd.DataFrame.from_dict(history8_2.history)\n",
    "df_hist8_2[\"Epoch\"] = np.arange(1, len(df_hist8_2) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax6 = df_hist8_2.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax6.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax6.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax6.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KhWmqQa8eyG2",
   "metadata": {
    "id": "KhWmqQa8eyG2"
   },
   "source": [
    "[BACK TO TOC](#toc)\n",
    "    \n",
    "<a id='transferlearning'></a>\n",
    "\n",
    "# <font color = 'darkblue'> 4. Transferlearning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uDUplF1QekWl",
   "metadata": {
    "id": "uDUplF1QekWl"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv4\">\n",
    "\n",
    "## 4.1. Transferlearning VGG16 model\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eab7c4",
   "metadata": {
    "id": "10eab7c4"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c1f4d",
   "metadata": {
    "id": "160c1f4d"
   },
   "source": [
    "Inspired by: https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YI13LJNGe5fO",
   "metadata": {
    "id": "YI13LJNGe5fO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VNlVGMm8sRgB",
   "metadata": {
    "id": "VNlVGMm8sRgB"
   },
   "outputs": [],
   "source": [
    "## Loading VGG16 model\n",
    "input_shape_vgg=batch_x_train_scaled[0].shape\n",
    "vgg16_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape_vgg)\n",
    "vgg16_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GaqVCSvFhaVZ",
   "metadata": {
    "id": "GaqVCSvFhaVZ"
   },
   "outputs": [],
   "source": [
    "ds_train_vgg16 = ds_train_encoded.map(lambda x, y: (preprocess_input(x), y))\n",
    "batch_x_train_vgg16, batch_y_train_vgg16 = next(iter(ds_train_vgg16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2sArWMnrimjb",
   "metadata": {
    "id": "2sArWMnrimjb"
   },
   "outputs": [],
   "source": [
    "ds_val_vgg16 = ds_val_encoded.map(lambda x, y: (preprocess_input(x), y))\n",
    "batch_x_val_vgg16, batch_y_val_vgg16 = next(iter(ds_val_vgg16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yJGrVy7SsRyk",
   "metadata": {
    "id": "yJGrVy7SsRyk"
   },
   "outputs": [],
   "source": [
    "vgg16_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JO1nnyUJe5oe",
   "metadata": {
    "id": "JO1nnyUJe5oe"
   },
   "outputs": [],
   "source": [
    "vgg16 = Sequential([vgg16_base,\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(50, activation='relu'),\n",
    "                    layers.Dense(20, activation='relu'),\n",
    "                    layers.Dense(units=6, activation=\"softmax\")               \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e42c9",
   "metadata": {
    "id": "7f4e42c9"
   },
   "outputs": [],
   "source": [
    "model=vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398557c6",
   "metadata": {
    "id": "398557c6"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c302d0d",
   "metadata": {
    "id": "4c302d0d"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'vgg16.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388bb7a5",
   "metadata": {
    "id": "388bb7a5"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9c52d",
   "metadata": {
    "id": "69e9c52d"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd1697d",
   "metadata": {
    "id": "9bd1697d"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uXG8nP41e5wv",
   "metadata": {
    "id": "uXG8nP41e5wv"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "vgg16.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "  metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'],\n",
    "  weighted_metrics= ['accuracy']\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HFvXt_qSvl-A",
   "metadata": {
    "id": "HFvXt_qSvl-A"
   },
   "outputs": [],
   "source": [
    "history_vgg16 = vgg16.fit(ds_train_vgg16 ,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          epochs=epochs,\n",
    "                          validation_data=ds_val_vgg16,\n",
    "                          class_weight=weights,\n",
    "                          callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e828dafd",
   "metadata": {
    "id": "e828dafd"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9lNGhouRmuRS",
   "metadata": {
    "id": "9lNGhouRmuRS"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_histvgg = pd.DataFrame.from_dict(history_vgg16.history)\n",
    "df_histvgg[\"Epoch\"] = np.arange(1, len(df_histvgg) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax = df_hist1.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ln1hLlos5xr1",
   "metadata": {
    "id": "ln1hLlos5xr1"
   },
   "source": [
    "<a class=\"anchor\" id=\"CNNv4\">\n",
    "\n",
    "## 4.2. Transferlearning ResNet50 model\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab09f73",
   "metadata": {
    "id": "1ab09f73"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evJIY4Z0ocZo",
   "metadata": {
    "id": "evJIY4Z0ocZo"
   },
   "source": [
    "#### Preprocessing Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HYBoDD6PDS5n",
   "metadata": {
    "id": "HYBoDD6PDS5n"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "ds_train_resnet = ds_train_encoded.map(lambda x, y: (preprocess_input(x), y))\n",
    "batch_x_train_resnet, batch_y_train_resnet = next(iter(ds_train_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p1A_1y6-DS5o",
   "metadata": {
    "id": "p1A_1y6-DS5o"
   },
   "outputs": [],
   "source": [
    "ds_val_resnet = ds_val_encoded.map(lambda x, y: (preprocess_input(x), y))\n",
    "batch_x_val_resnet, batch_y_val_resnet = next(iter(ds_val_resnet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HIb3xlRQlSP2",
   "metadata": {
    "id": "HIb3xlRQlSP2"
   },
   "source": [
    "#### First Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45742d",
   "metadata": {
    "id": "9a45742d"
   },
   "outputs": [],
   "source": [
    "# Freeze the layers of the ResNet50 model\n",
    "\n",
    "resnet = ResNet50(include_top = False, input_shape = (128,128,3),weights = 'imagenet', classifier_activation = 'softmax')\n",
    "\n",
    "for layer in resnet.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "resnet = Sequential([resnet,\n",
    "                   #layers.Flatten(),\n",
    "                   layers.GlobalAveragePooling2D(),\n",
    "                   layers.Dense(128, activation='relu'),\n",
    "                   layers.Dense(units = 6, activation='softmax'),\n",
    "])\n",
    "\n",
    "print(resnet.summary())\n",
    "\n",
    "resnet.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888411b4",
   "metadata": {
    "id": "888411b4"
   },
   "outputs": [],
   "source": [
    "model=resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed8d4b",
   "metadata": {
    "id": "efed8d4b"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe62cd",
   "metadata": {
    "id": "98fe62cd"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'resnet.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b35ee",
   "metadata": {
    "id": "909b35ee"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235137d5",
   "metadata": {
    "id": "235137d5"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7b60b",
   "metadata": {
    "id": "64c7b60b"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wdTYoXZ-OXB2",
   "metadata": {
    "id": "wdTYoXZ-OXB2"
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "#Adding early stopping to help choosing the best number of epochs\n",
    "#code from: https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/\n",
    "\n",
    "#Train\n",
    "history_resnet = resnet.fit(ds_train_resnet , batch_size=batch_size, shuffle=shuffle, epochs=epochs, validation_data=ds_val_resnet, \n",
    "                          class_weight=weights, callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1abb5",
   "metadata": {
    "id": "f5e1abb5"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vb8yYiqlOhC0",
   "metadata": {
    "id": "vb8yYiqlOhC0"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist_restnet = pd.DataFrame.from_dict(history_resnet.history)\n",
    "df_hist_restnet[\"Epoch\"] = np.arange(1, len(df_hist_restnet) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax = df_hist_restnet.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa_ql34LlL5n",
   "metadata": {
    "id": "fa_ql34LlL5n"
   },
   "source": [
    "#### Testing layers -> Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc38d86",
   "metadata": {
    "id": "7fc38d86"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d367c1",
   "metadata": {
    "id": "07d367c1"
   },
   "outputs": [],
   "source": [
    "resnet = ResNet50(include_top = False, input_shape = (128,128,3),weights = 'imagenet', classifier_activation = 'softmax')\n",
    "\n",
    "# Freeze the layers of the ResNet50 model\n",
    "for layer in resnet.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "resnet_2 = Sequential([resnet,\n",
    "                   #layers.Flatten(),\n",
    "                   layers.GlobalAveragePooling2D(),\n",
    "                   layers.Dropout(0.2),\n",
    "                   layers.BatchNormalization(),\n",
    "                   layers.Dropout(0.2),\n",
    "                   layers.Dense(128, activation='relu'),\n",
    "                   layers.Dropout(0.1),\n",
    "                   layers.Dense(units = 6, activation='softmax')\n",
    "])\n",
    "\n",
    "print(resnet_2.summary())\n",
    "\n",
    "resnet_2.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6ffc8",
   "metadata": {
    "id": "b3d6ffc8"
   },
   "outputs": [],
   "source": [
    "model=resnet_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32327808",
   "metadata": {
    "id": "32327808"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3cb5f",
   "metadata": {
    "id": "dbd3cb5f"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'resnet_2.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545672a1",
   "metadata": {
    "id": "545672a1"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef2488",
   "metadata": {
    "id": "afef2488"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f9d2c",
   "metadata": {
    "id": "d04f9d2c"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kEV7fLqMO7d1",
   "metadata": {
    "id": "kEV7fLqMO7d1"
   },
   "source": [
    "Might be underfitting since the lines are very flat\n",
    "According to Andrew Ng, the best methods of dealing with an underfitting model is trying a bigger neural network (adding new layers or increasing the number of neurons in existing layers) or training the model a little bit longer.\n",
    "https://www.mikulskibartosz.name/how-to-deal-with-underfitting-and-overfitting-in-deep-learning/#:~:text=According%20to%20Andrew%20Ng%2C%20the,model%20a%20little%20bit%20longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UC4pGG0xJfMO",
   "metadata": {
    "id": "UC4pGG0xJfMO"
   },
   "outputs": [],
   "source": [
    "#code inspired from: https://www.kaggle.com/code/imsparsh/food-classifier-mobilenetv2-resnet50-vgg16#Training-different-models\n",
    "\n",
    "\n",
    "# Model training (v1)\n",
    "#Adding early stopping to help choosing the best number of epochs\n",
    "#code from: https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/\n",
    "\n",
    "#Train\n",
    "history_resnet_2 = resnet_2.fit(ds_train_resnet , batch_size=batch_size, shuffle=shuffle, epochs=epochs, validation_data=ds_val_resnet, \n",
    "                          class_weight=weights, callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7104f7d",
   "metadata": {
    "id": "f7104f7d"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jtqaUbsfTDV5",
   "metadata": {
    "id": "jtqaUbsfTDV5"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist_restnet_2 = pd.DataFrame.from_dict(history_resnet_2.history)\n",
    "df_hist_restnet_2[\"Epoch\"] = np.arange(1, len(df_hist_restnet_2) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax = df_hist_restnet_2.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7N2rncE6lDie",
   "metadata": {
    "id": "7N2rncE6lDie"
   },
   "source": [
    "#### Bigger DropOut -> Does not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e34fd81",
   "metadata": {
    "id": "6e34fd81"
   },
   "outputs": [],
   "source": [
    "# #Clear previous logs\n",
    "\n",
    "# #collab\n",
    "!rm -rf /logs/ \n",
    "\n",
    "\n",
    "# #jupyter using Windows based on https://www.machinelearningnuggets.com/tensorboard-tutorial/\n",
    "# try:\n",
    "#     shutil.rmtree('logs')\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444f1d4",
   "metadata": {
    "id": "9444f1d4"
   },
   "outputs": [],
   "source": [
    "#code inspired from: https://www.kaggle.com/code/imsparsh/food-classifier-mobilenetv2-resnet50-vgg16#Training-different-models\n",
    "\n",
    "resnet = ResNet50(include_top = False, input_shape = (128,128,3),weights = 'imagenet', classifier_activation = 'softmax')\n",
    "\n",
    "# Freeze the layers of the ResNet50 model\n",
    "for layer in resnet.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "resnet_3 = Sequential([resnet,\n",
    "                   #layers.Flatten(),\n",
    "                   layers.GlobalAveragePooling2D(),\n",
    "                   layers.Dropout(0.8),\n",
    "                   layers.BatchNormalization(),\n",
    "                   layers.Dropout(0.5),\n",
    "                   layers.Dense(128, activation='relu'),\n",
    "                   layers.Dropout(0.1),\n",
    "                   layers.Dense(units = 6, activation='softmax')\n",
    "])\n",
    "\n",
    "print(resnet_3.summary())\n",
    "\n",
    "resnet_3.compile(\n",
    "  optimizer= optimizers.Adam(learning_rate=learning_rate),\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "    metrics= [tfa.metrics.f_scores.F1Score(num_classes=6,average=\"weighted\", name = 'f1_score'), 'accuracy'], weighted_metrics= ['accuracy'])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0d75e",
   "metadata": {
    "id": "86c0d75e"
   },
   "outputs": [],
   "source": [
    "model=resnet_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738bd68",
   "metadata": {
    "id": "1738bd68"
   },
   "source": [
    "Callbacks API setup (inspired in the class code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72301a",
   "metadata": {
    "id": "dc72301a"
   },
   "outputs": [],
   "source": [
    "#checkpoint_filepath = '/content/drive/MyDrive/IMS_DeepLearning'\n",
    "checkpoint_filepath = 'resnet_3.weights.best.hdf6'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_f1_score\",\n",
    "    min_delta=0,\n",
    "    mode=\"max\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8c9a7",
   "metadata": {
    "id": "50d8c9a7"
   },
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Defining the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71473aa",
   "metadata": {
    "id": "a71473aa"
   },
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions_raw = model.predict(batch_x_val_scaled)\n",
    "    predictions = np.argmax(predictions_raw, axis=1)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(np.argmax(batch_y_val_scaled, axis=1), predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f1103f",
   "metadata": {
    "id": "a4f1103f"
   },
   "outputs": [],
   "source": [
    "# Defining the per-epoch callback.\n",
    "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8m0793-g27C",
   "metadata": {
    "id": "a8m0793-g27C"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Model training (v1)\n",
    "#Adding early stopping to help choosing the best number of epochs\n",
    "#code from: https://www.geeksforgeeks.org/choose-optimal-number-of-epochs-to-train-a-neural-network-in-keras/\n",
    "\n",
    "#Train\n",
    "history_resnet_3 = resnet_3.fit(ds_train_resnet , batch_size=batch_size, shuffle=shuffle, epochs=epochs, validation_data=ds_val_resnet, \n",
    "                          class_weight=weights, callbacks =[early_stopping, model_checkpoint, tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b26d12",
   "metadata": {
    "id": "31b26d12"
   },
   "outputs": [],
   "source": [
    "#Star tensorboard\n",
    "\n",
    "%tensorboard --logdir logs/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RHIN20zyg27D",
   "metadata": {
    "id": "RHIN20zyg27D"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame object\n",
    "df_hist_restnet_3 = pd.DataFrame.from_dict(history_resnet_3.history)\n",
    "df_hist_restnet_3[\"Epoch\"] = np.arange(1, len(df_hist_restnet_3) + 1, 1)\n",
    "# Plot learning curves\n",
    "secondary_y = [\"f1_score\", \"val_f1_score\"]\n",
    "ax = df_hist_restnet_3.plot(x=\"Epoch\", y=['loss', 'val_loss'] + secondary_y,\n",
    "                   secondary_y = secondary_y,\n",
    "                   kind=\"line\", figsize=(6, 3), grid=True, legend=True,\n",
    "                   ylabel=\"Cross-entropy\", \n",
    "                   xlabel=\"Epoch\", title=\"Learning curves\",                  \n",
    "                   color=['darkred', 'indianred', \"darkblue\", \"royalblue\"], alpha=0.75, fontsize=10)\n",
    "ax.right_ax.set_ylabel(\"Accuracy\")\n",
    "ax.right_ax.legend(loc=(0.25, -0.45), framealpha=1.0)\n",
    "ax.legend(loc=(0, -0.45), framealpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7KSEhvT9wXaL",
   "metadata": {
    "id": "7KSEhvT9wXaL"
   },
   "source": [
    "[BACK TO TOC](#toc)\n",
    "    \n",
    "<a id='transferlearning'></a>\n",
    "\n",
    "# <font color = 'darkblue'> 4. Saving the Models </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F7L5OouPwZmy",
   "metadata": {
    "id": "F7L5OouPwZmy"
   },
   "outputs": [],
   "source": [
    "cnn1.save('/content/drive/MyDrive/IMS_DeepLearning/Models')\n",
    "cnn2.save('/content/drive/MyDrive/IMS_DeepLearning/Models')\n",
    "cnn3.save('/content/drive/MyDrive/IMS_DeepLearning/Models')\n",
    "#cnn4.save('/content/drive/MyDrive/IMS_DeepLearning/Models')\n",
    "cnn5.save('/content/drive/MyDrive/IMS_DeepLearning/Models')\n",
    "cnn6.save('/content/drive/MyDrive/IMS_DeepLearning/Models')\n",
    "cnn7.save('/content/drive/MyDrive/IMS_DeepLearning/Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pZ6MVcAfzBLs",
   "metadata": {
    "id": "pZ6MVcAfzBLs"
   },
   "outputs": [],
   "source": [
    "vgg16.save('vgg16','/content/drive/MyDrive/IMS_DeepLearning/Models')\n",
    "resnet.save('resnet','/content/drive/MyDrive/IMS_DeepLearning/Models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Tbn-N5bwxuSn",
   "metadata": {
    "id": "Tbn-N5bwxuSn"
   },
   "source": [
    "[BACK TO TOC](#toc)\n",
    "    \n",
    "<a id='transferlearning'></a>\n",
    "\n",
    "# <font color = 'darkblue'> 4. Testing with Test dataset </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jBdpHG6m2GBm",
   "metadata": {
    "id": "jBdpHG6m2GBm"
   },
   "source": [
    "<a class=\"anchor\" id=\"Datapreprocessing\">\n",
    "\n",
    "## Importing \n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zFCL5RYWxyd8",
   "metadata": {
    "id": "zFCL5RYWxyd8"
   },
   "outputs": [],
   "source": [
    "data_dir_test = '/content/drive/MyDrive/IMS_DeepLearning/dataset_dishes/test'\n",
    "ds_test = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir_test,\n",
    "  image_size=image_size,\n",
    "    crop_to_aspect_ratio=crop_to_aspect_ratio,\n",
    "    color_mode=color_mode,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle,\n",
    "    seed=seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5yf0mv2G0Vpc",
   "metadata": {
    "id": "5yf0mv2G0Vpc"
   },
   "outputs": [],
   "source": [
    "#img = ds_test[0]\n",
    "# img = Image.fromarray(img, 'RGB')\n",
    "# img.save('outfile.jpg')\n",
    "# cv2.imwrite('myImage.png',img)\n",
    "\n",
    "# img = image.load_img('outfile.jpg', target_size=(200, 200))\n",
    "# img_tensor = image.img_to_array(img)\n",
    "#img_tensor = np.expand_dims(img, axis=0)\n",
    "#img_tensor /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5VNuN4Zx0z-k",
   "metadata": {
    "id": "5VNuN4Zx0z-k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "WDI44FPL00Hf",
   "metadata": {
    "id": "WDI44FPL00Hf"
   },
   "source": [
    "<a class=\"anchor\" id=\"Datapreprocessing\">\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "op1d0saY00Hg",
   "metadata": {
    "id": "op1d0saY00Hg"
   },
   "source": [
    "Encoding the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usOs-trV00Hg",
   "metadata": {
    "id": "usOs-trV00Hg"
   },
   "outputs": [],
   "source": [
    "ds_test_encoded = ds_test.map(lambda x, y: (x, encoding(y)))\n",
    "batch_x_test_encoded, batch_y_test_encoded = next(iter(ds_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w7E3UxF000Hg",
   "metadata": {
    "id": "w7E3UxF000Hg"
   },
   "outputs": [],
   "source": [
    "rescaling = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qNwxTuWt00Hg",
   "metadata": {
    "id": "qNwxTuWt00Hg"
   },
   "outputs": [],
   "source": [
    "ds_test_scaled = ds_test_encoded.map(lambda x, y: (rescaling(x), y))\n",
    "batch_x_test_scaled, batch_y_test_scaled = next(iter(ds_test_scaled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fvinq4jE1c9O",
   "metadata": {
    "id": "fvinq4jE1c9O"
   },
   "source": [
    "<a class=\"anchor\" id=\"Datapreprocessing\">\n",
    "\n",
    "## Results with CNN1\n",
    "\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mMFcbAcnzuBu",
   "metadata": {
    "id": "mMFcbAcnzuBu"
   },
   "outputs": [],
   "source": [
    "img = batch_x_test_encoded[0]\n",
    "\n",
    "#predict = (vgg16.predict(img))\n",
    "\n",
    "cnn1.evaluate(batch_x_test_scaled, batch_y_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33984383",
   "metadata": {
    "id": "33984383"
   },
   "outputs": [],
   "source": [
    "classes=batch_y_test_scaled.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d39c8",
   "metadata": {
    "id": "896d39c8"
   },
   "outputs": [],
   "source": [
    "classes=np.argmax(classes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb7e040",
   "metadata": {
    "id": "cfb7e040"
   },
   "outputs": [],
   "source": [
    "cnn1.load_weights('cnn1.weights.best.hdf6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ufjWzA_O2NrP",
   "metadata": {
    "id": "ufjWzA_O2NrP"
   },
   "outputs": [],
   "source": [
    "predicts= cnn1.predict(ds_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e15c4",
   "metadata": {
    "id": "780e15c4"
   },
   "outputs": [],
   "source": [
    "predict_classes=np.argmax(predicts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff848280",
   "metadata": {
    "id": "ff848280"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aef3a8",
   "metadata": {
    "id": "59aef3a8"
   },
   "outputs": [],
   "source": [
    "acc= accuracy_score(classes,predict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee148ac",
   "metadata": {
    "id": "4ee148ac"
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b83d5",
   "metadata": {
    "id": "313b83d5"
   },
   "outputs": [],
   "source": [
    "predict_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vJu7JH8Jn70h",
   "metadata": {
    "id": "vJu7JH8Jn70h"
   },
   "source": [
    "## Results with ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unONqnR9orqz",
   "metadata": {
    "id": "unONqnR9orqz"
   },
   "outputs": [],
   "source": [
    "ds_test_resnet = ds_test_encoded.map(lambda x, y: (preprocess_input(x), y))\n",
    "batch_x_test_resnet, batch_y_test_resnet = next(iter(ds_test_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NIVPjm6Qo-5x",
   "metadata": {
    "id": "NIVPjm6Qo-5x"
   },
   "outputs": [],
   "source": [
    "img = batch_x_test_resnet[0]\n",
    "\n",
    "#predict = (vgg16.predict(img))\n",
    "\n",
    "resnet_2.evaluate(batch_x_test_resnet, batch_y_test_resnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pk7YkRELo-5z",
   "metadata": {
    "id": "pk7YkRELo-5z"
   },
   "outputs": [],
   "source": [
    "classes=batch_y_test_resnet.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HhgDdl4xo-5z",
   "metadata": {
    "id": "HhgDdl4xo-5z"
   },
   "outputs": [],
   "source": [
    "classes=np.argmax(classes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s54c7dY3o-5z",
   "metadata": {
    "id": "s54c7dY3o-5z"
   },
   "outputs": [],
   "source": [
    "#resnet_2.load_weights('rest.weights.best.hdf6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "npBrAAxOo-5z",
   "metadata": {
    "id": "npBrAAxOo-5z"
   },
   "outputs": [],
   "source": [
    "predicts= resnet_2.predict(ds_test_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A4Iqw_MDo-5z",
   "metadata": {
    "id": "A4Iqw_MDo-5z"
   },
   "outputs": [],
   "source": [
    "predict_classes=np.argmax(predicts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wbWO1Skpo-5z",
   "metadata": {
    "id": "wbWO1Skpo-5z"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OQZ2Kef8o-5z",
   "metadata": {
    "id": "OQZ2Kef8o-5z"
   },
   "outputs": [],
   "source": [
    "acc= accuracy_score(classes,predict_classes)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F2uSBh9ir5Va",
   "metadata": {
    "id": "F2uSBh9ir5Va"
   },
   "outputs": [],
   "source": [
    "print('Classes:',classes)\n",
    "print('Predict:',predict_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YqnzEuAZCcyp",
   "metadata": {
    "id": "YqnzEuAZCcyp"
   },
   "source": [
    "## CNN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yu1c0UO5Cmhv",
   "metadata": {
    "id": "yu1c0UO5Cmhv"
   },
   "outputs": [],
   "source": [
    "img = batch_x_test_encoded[0]\n",
    "\n",
    "#predict = (vgg16.predict(img))\n",
    "\n",
    "cnn_2.evaluate(batch_x_test_scaled, batch_y_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyfGyvnLCmhw",
   "metadata": {
    "id": "lyfGyvnLCmhw"
   },
   "outputs": [],
   "source": [
    "classes=batch_y_test_scaled.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ywvA1FL0Cmhw",
   "metadata": {
    "id": "ywvA1FL0Cmhw"
   },
   "outputs": [],
   "source": [
    "classes=np.argmax(classes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JxDZ0wfUCmhw",
   "metadata": {
    "id": "JxDZ0wfUCmhw"
   },
   "outputs": [],
   "source": [
    "cnn2.load_weights('cnn2.weights.best.hdf6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UMUdavsBCmhw",
   "metadata": {
    "id": "UMUdavsBCmhw"
   },
   "outputs": [],
   "source": [
    "predicts= cnn2.predict(ds_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3-7-DPs9Cmhw",
   "metadata": {
    "id": "3-7-DPs9Cmhw"
   },
   "outputs": [],
   "source": [
    "predict_classes=np.argmax(predicts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3NuH-gtgCmhx",
   "metadata": {
    "id": "3NuH-gtgCmhx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kYrH5R3KCmhx",
   "metadata": {
    "id": "kYrH5R3KCmhx"
   },
   "outputs": [],
   "source": [
    "acc= accuracy_score(classes,predict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GBe5pAhICmhx",
   "metadata": {
    "id": "GBe5pAhICmhx"
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32kkcHpmCmhx",
   "metadata": {
    "id": "32kkcHpmCmhx"
   },
   "outputs": [],
   "source": [
    "predict_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-CtrZ_j0rUHd",
   "metadata": {
    "id": "-CtrZ_j0rUHd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_it3OidArcio",
   "metadata": {
    "id": "_it3OidArcio"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2FnZgBLurfjF",
   "metadata": {
    "id": "2FnZgBLurfjF"
   },
   "source": [
    "## Resultados Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XOv-0YN1rgwA",
   "metadata": {
    "id": "XOv-0YN1rgwA"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn1.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn1.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn1.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q7A1MpWPrjet",
   "metadata": {
    "id": "q7A1MpWPrjet"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn2_1.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn2_1.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn2_1.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6orroGpGsB9H",
   "metadata": {
    "id": "6orroGpGsB9H"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn2_2.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn2_2.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn2_2.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TaziJMJ4rkOG",
   "metadata": {
    "id": "TaziJMJ4rkOG"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn3.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn3.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn3.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59yW7foLrky8",
   "metadata": {
    "id": "59yW7foLrky8"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn4.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn4.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn4.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xGKRbL9prlcu",
   "metadata": {
    "id": "xGKRbL9prlcu"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn5.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn5.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn5.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IkshidQ-rl-9",
   "metadata": {
    "id": "IkshidQ-rl-9"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn6_1.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn6_1.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn6_1.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1JeHcJS4sFcM",
   "metadata": {
    "id": "1JeHcJS4sFcM"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn6_2.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn6_2.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn6_2.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XvAYv1fMrnjt",
   "metadata": {
    "id": "XvAYv1fMrnjt"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn7.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn7.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn7.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ukb7zOR1roDs",
   "metadata": {
    "id": "Ukb7zOR1roDs"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = cnn8.evaluate(batch_x_train_scaled,batch_y_train_scaled, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn8.evaluate(batch_x_val_scaled,batch_y_val_scaled, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = cnn8.evaluate(batch_x_test_scaled,batch_y_test_scaled, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gTTosCBD5Bnz",
   "metadata": {
    "id": "gTTosCBD5Bnz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OYL5eo6r4H1S",
   "metadata": {
    "id": "OYL5eo6r4H1S"
   },
   "outputs": [],
   "source": [
    "ds_test_vgg16 = ds_test_encoded.map(lambda x, y: (preprocess_input(x), y))\n",
    "batch_x_test_vgg16, batch_y_test_vgg16 = next(iter(ds_test_vgg16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T3qyjUhy0M-0",
   "metadata": {
    "id": "T3qyjUhy0M-0"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = vgg16.evaluate(batch_x_train_vgg16,batch_y_train_vgg16, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = vgg16.evaluate(batch_x_val_vgg16,batch_y_val_vgg16, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = vgg16.evaluate(batch_x_test_vgg16,batch_y_test_vgg16, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8CKdf_gq5UVm",
   "metadata": {
    "id": "8CKdf_gq5UVm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3Gvy80_5UvY",
   "metadata": {
    "id": "b3Gvy80_5UvY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26mbo9O5UvY",
   "metadata": {
    "id": "e26mbo9O5UvY"
   },
   "outputs": [],
   "source": [
    "ds_test_resnet = ds_test_encoded.map(lambda x, y: (preprocess_input(x), y))\n",
    "batch_x_test_resnet, batch_y_test_resnet = next(iter(ds_test_resnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NL5FIcgz0Ny_",
   "metadata": {
    "id": "NL5FIcgz0Ny_"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = resnet.evaluate(batch_x_train_resnet,batch_y_train_resnet, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = resnet.evaluate(batch_x_val_resnet,batch_y_val_resnet, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = resnet.evaluate(batch_x_test_resnet,batch_y_test_resnet, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vFcs84la0Wg7",
   "metadata": {
    "id": "vFcs84la0Wg7"
   },
   "outputs": [],
   "source": [
    "score, f1_score, acc, weighted_accuracy = resnet_2.evaluate(batch_x_train_resnet,batch_y_train_resnet, verbose=0)\n",
    "\n",
    "print(\"Training loss score: %0.3f\" % (score))\n",
    "print(\"Training f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Training accuracy: %0.3f\" % (acc))\n",
    "print(\"Training weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = resnet_2.evaluate(batch_x_val_resnet,batch_y_val_resnet, verbose=0)\n",
    "\n",
    "print(\"Validation loss score: %0.3f\" % (score))\n",
    "print(\"Validation f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Validation accuracy: %0.3f\" % (acc))\n",
    "print(\"Validation weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "score, f1_score, acc, weighted_accuracy = resnet_2.evaluate(batch_x_test_resnet,batch_y_test_resnet, verbose=0)\n",
    "\n",
    "print(\"Test loss score: %0.3f\" % (score))\n",
    "print(\"Test f1-score: %0.3f\" % (f1_score))\n",
    "print(\"Test accuracy: %0.3f\" % (acc))\n",
    "print(\"Test weighted_accuracy: %0.3f\" % (weighted_accuracy))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gwcn8lXO2bFr",
   "metadata": {
    "id": "Gwcn8lXO2bFr"
   },
   "outputs": [],
   "source": [
    "resnet_2.evaluate(batch_x_test_resnet, batch_y_test_resnet)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "4a149aa4",
    "555260b7",
    "0e077650",
    "ccc5386c",
    "014367d1",
    "A_Tl191TpquY",
    "aba17414",
    "81974e5f",
    "744709bc",
    "ed47742f",
    "l8ZiRxJC9AeD",
    "OU9iv6asqiv4",
    "teJEB-Taqwk_",
    "LmyE08xRq0yh",
    "UeEZprbWiygK",
    "a145163e",
    "uDUplF1QekWl",
    "evJIY4Z0ocZo",
    "HIb3xlRQlSP2",
    "fa_ql34LlL5n",
    "7N2rncE6lDie",
    "7KSEhvT9wXaL",
    "jBdpHG6m2GBm",
    "WDI44FPL00Hf",
    "vJu7JH8Jn70h"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
